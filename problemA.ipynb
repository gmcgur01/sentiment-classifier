{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem A: Bag off Words and Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports training data from files\n",
    "def load_train_data():\n",
    "    data_dir = \"data_reviews\"\n",
    "    x_train_df = pd.read_csv(os.path.join(data_dir, \"x_train.csv\"))\n",
    "    y_train_df = pd.read_csv(os.path.join(data_dir, \"y_train.csv\"))\n",
    "    return x_train_df, y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_website(x_N):\n",
    "\n",
    "    N = x_N.shape[0]\n",
    "\n",
    "    x_amazon = [(x_N[i,1], i) for i in range(N) if x_N[i,0] == \"amazon\"]\n",
    "    x_imdb = [(x_N[i,1], i) for i in range(N) if x_N[i,0] == \"imdb\"]\n",
    "    x_yelp = [(x_N[i,1], i) for i in range(N) if x_N[i,0] == \"yelp\"]\n",
    "    \n",
    "    return x_amazon, x_imdb, x_yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    data_dir = \"data_reviews\"\n",
    "    x_test_df = pd.read_csv(os.path.join(data_dir, \"x_test.csv\"))\n",
    "    return x_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_word_freq(x_train_N):\n",
    "    # min_df sets sets a minimum number of times a given token needs to be\n",
    "    # included in a text entry to be a part of the vector\n",
    "    vectorizer = CountVectorizer(min_df=4, binary=False)\n",
    "    x_vec_N = vectorizer.fit_transform(x_train_N)\n",
    "\n",
    "    dense_arr = x_vec_N.toarray()\n",
    "\n",
    "    freq = [\n",
    "        (term, np.sum(dense_arr[:, index]))\n",
    "        for term, index in list(vectorizer.vocabulary_.items())\n",
    "    ]\n",
    "\n",
    "    for term, count in sorted(freq, key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{term} -- {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for BoW representation + logistic regression classifier\n",
    "def make_bow_classifier_pipeline():\n",
    "    pipeline = sklearn.pipeline.Pipeline(\n",
    "        steps=[\n",
    "            # turn data into BoW feature representation\n",
    "            (\n",
    "                \"bow_feature_extractor\",\n",
    "                CountVectorizer(min_df=2, max_df=1.0, ngram_range=(1, 1)),\n",
    "            ),\n",
    "            # Given features construct the classifier (w/ hyperparam selection)\n",
    "            (\n",
    "                \"classifier\",\n",
    "                sklearn.linear_model.LogisticRegression(C=1.0, max_iter=100000),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hyperparam_grid():\n",
    "\n",
    "    hyperparam_grid = {}\n",
    "\n",
    "    hyperparam_grid[\"bow_feature_extractor__min_df\"] = [1, 2, 3, 4, 8]\n",
    "    hyperparam_grid[\"bow_feature_extractor__max_df\"] = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3]\n",
    "    hyperparam_grid[\"classifier__C\"] = np.logspace(-2, 2, 20)\n",
    "\n",
    "    return hyperparam_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and train model using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df, y_train_df = load_train_data()\n",
    "\n",
    "x_test_df = load_test_data()\n",
    "\n",
    "x_amazon, x_imdb, x_yelp = split_by_website(x_train_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_text, amazon_indices = zip(*x_amazon)\n",
    "imdb_text, imdb_indices = zip(*x_imdb)\n",
    "yelp_text, yelp_indices = zip(*x_yelp)\n",
    "\n",
    "amazon_text = np.asarray(list(amazon_text))\n",
    "amazon_indices = np.asarray(list(amazon_indices))\n",
    "\n",
    "imdb_text = np.asarray(list(imdb_text))\n",
    "imdb_indices = np.asarray(list(imdb_indices))\n",
    "\n",
    "yelp_text = np.asarray(list(yelp_text))\n",
    "yelp_indices = np.asarray(list(yelp_indices))\n",
    "\n",
    "y_train_N = y_train_df.to_numpy()\n",
    "\n",
    "y_amazon = y_train_N[amazon_indices][:,0]\n",
    "y_imdb = y_train_N[imdb_indices][:,0]\n",
    "y_yelp = y_train_N[yelp_indices][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_text, y_amazon = shuffle(amazon_text, y_amazon, random_state=2)\n",
    "imdb_text, y_imdb = shuffle(imdb_text, y_imdb, random_state=2)\n",
    "yelp_text, y_yelp = shuffle(yelp_text, y_yelp, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;bow_feature_extractor&#x27;,\n",
       "                                        CountVectorizer(min_df=2)),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=100000))]),\n",
       "             param_grid={&#x27;bow_feature_extractor__max_df&#x27;: [1.0, 0.9, 0.8, 0.7,\n",
       "                                                           0.6, 0.5, 0.4, 0.3],\n",
       "                         &#x27;bow_feature_extractor__min_df&#x27;: [1, 2, 3, 4, 8],\n",
       "                         &#x27;classifier__C&#x27;: array([1.00000000e-02, 1.62377674e-02, 2.63665090e-02, 4.28133240e-02,\n",
       "       6.95192796e-02, 1.12883789e-01, 1.83298071e-01, 2.97635144e-01,\n",
       "       4.83293024e-01, 7.84759970e-01, 1.27427499e+00, 2.06913808e+00,\n",
       "       3.35981829e+00, 5.45559478e+00, 8.85866790e+00, 1.43844989e+01,\n",
       "       2.33572147e+01, 3.79269019e+01, 6.15848211e+01, 1.00000000e+02])},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;bow_feature_extractor&#x27;,\n",
       "                                        CountVectorizer(min_df=2)),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=100000))]),\n",
       "             param_grid={&#x27;bow_feature_extractor__max_df&#x27;: [1.0, 0.9, 0.8, 0.7,\n",
       "                                                           0.6, 0.5, 0.4, 0.3],\n",
       "                         &#x27;bow_feature_extractor__min_df&#x27;: [1, 2, 3, 4, 8],\n",
       "                         &#x27;classifier__C&#x27;: array([1.00000000e-02, 1.62377674e-02, 2.63665090e-02, 4.28133240e-02,\n",
       "       6.95192796e-02, 1.12883789e-01, 1.83298071e-01, 2.97635144e-01,\n",
       "       4.83293024e-01, 7.84759970e-01, 1.27427499e+00, 2.06913808e+00,\n",
       "       3.35981829e+00, 5.45559478e+00, 8.85866790e+00, 1.43844989e+01,\n",
       "       2.33572147e+01, 3.79269019e+01, 6.15848211e+01, 1.00000000e+02])},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;bow_feature_extractor&#x27;, CountVectorizer(min_df=2)),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=100000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(min_df=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=100000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('bow_feature_extractor',\n",
       "                                        CountVectorizer(min_df=2)),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=100000))]),\n",
       "             param_grid={'bow_feature_extractor__max_df': [1.0, 0.9, 0.8, 0.7,\n",
       "                                                           0.6, 0.5, 0.4, 0.3],\n",
       "                         'bow_feature_extractor__min_df': [1, 2, 3, 4, 8],\n",
       "                         'classifier__C': array([1.00000000e-02, 1.62377674e-02, 2.63665090e-02, 4.28133240e-02,\n",
       "       6.95192796e-02, 1.12883789e-01, 1.83298071e-01, 2.97635144e-01,\n",
       "       4.83293024e-01, 7.84759970e-01, 1.27427499e+00, 2.06913808e+00,\n",
       "       3.35981829e+00, 5.45559478e+00, 8.85866790e+00, 1.43844989e+01,\n",
       "       2.33572147e+01, 3.79269019e+01, 6.15848211e+01, 1.00000000e+02])},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_pipeline = make_bow_classifier_pipeline()\n",
    "amazon_hyperparam_grid = make_hyperparam_grid()\n",
    "\n",
    "amazon_grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    amazon_pipeline,\n",
    "    amazon_hyperparam_grid,\n",
    "    cv=10,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "imdb_pipeline = make_bow_classifier_pipeline()\n",
    "imdb_hyperparam_grid = make_hyperparam_grid()\n",
    "\n",
    "imdb_grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    imdb_pipeline,\n",
    "    imdb_hyperparam_grid,\n",
    "    cv=10,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "yelp_pipeline = make_bow_classifier_pipeline()\n",
    "yelp_hyperparam_grid = make_hyperparam_grid()\n",
    "\n",
    "yelp_grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    yelp_pipeline,\n",
    "    yelp_hyperparam_grid,\n",
    "    cv=10,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "grid_searchers = [amazon_grid_searcher, imdb_grid_searcher, yelp_grid_searcher]\n",
    "\n",
    "\n",
    "grid_searchers[0].fit(amazon_text, y_amazon)\n",
    "grid_searchers[1].fit(imdb_text, y_imdb)\n",
    "grid_searchers[2].fit(yelp_text, y_yelp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = [grid_searchers[i].best_estimator_ for i in range(3)]\n",
    "\n",
    "x_test_amazon, x_test_imdb, x_test_yelp = split_by_website(x_test_df.to_numpy())\n",
    "\n",
    "x_test_amazon_text, _ = zip(*x_test_amazon)\n",
    "x_test_imdb_text, _ = zip(*x_test_imdb)\n",
    "x_test_yelp_text, _ = zip(*x_test_yelp)\n",
    "\n",
    "x_test_amazon_text = np.asarray(x_test_amazon_text)\n",
    "x_test_imdb_text = np.asarray(x_test_imdb_text)\n",
    "x_test_yelp_text = np.asarray(x_test_yelp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.89925; best params: {'bow_feature_extractor__max_df': 1.0, 'bow_feature_extractor__min_df': 1, 'classifier__C': 37.92690190732246}\n",
      "best score: 0.8520000000000001; best params: {'bow_feature_extractor__max_df': 0.3, 'bow_feature_extractor__min_df': 1, 'classifier__C': 3.359818286283781}\n",
      "best score: 0.89175; best params: {'bow_feature_extractor__max_df': 0.3, 'bow_feature_extractor__min_df': 1, 'classifier__C': 3.359818286283781}\n"
     ]
    }
   ],
   "source": [
    "yhat_amazon = best_models[0].predict_proba(x_test_amazon_text)[:,1]\n",
    "yhat_imdb = best_models[1].predict_proba(x_test_imdb_text)[:,1]\n",
    "yhat_yelp = best_models[2].predict_proba(x_test_yelp_text)[:,1]\n",
    "\n",
    "yhat_test_N = np.concatenate((yhat_amazon, yhat_imdb, yhat_yelp))\n",
    "\n",
    "np.savetxt(\"yproba1_test.txt\", yhat_test_N)\n",
    "\n",
    "for searcher in grid_searchers:\n",
    "    best_params = searcher.best_params_\n",
    "    best_score = searcher.best_score_\n",
    "\n",
    "    print(f\"best score: {best_score}; best params:\", best_params)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of company label\n",
    "x_train_N = x_train_df.to_numpy()[:, 1]\n",
    "y_train_N = y_train_df.to_numpy()[:, 0]\n",
    "\n",
    "x_test_N = x_test_df.to_numpy()[:, 1]\n",
    "\n",
    "# shuffle dataset\n",
    "x_train_N, y_train_N = shuffle(x_train_N, y_train_N, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m hyperparam_grid \u001b[39m=\u001b[39m make_hyperparam_grid()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m grid_searcher \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmodel_selection\u001b[39m.\u001b[39mGridSearchCV(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     pipeline,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     hyperparam_grid,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     cv\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m grid_searcher\u001b[39m.\u001b[39;49mfit(x_train_N, y_train_N)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m best_model \u001b[39m=\u001b[39m grid_searcher\u001b[39m.\u001b[39mbest_estimator_\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/georgemcgurkin/Desktop/code/sentiment-classifier/problemA.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m best_params \u001b[39m=\u001b[39m grid_searcher\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[1;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    360\u001b[0m     cloned_transformer,\n\u001b[1;32m    361\u001b[0m     X,\n\u001b[1;32m    362\u001b[0m     y,\n\u001b[1;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m             )\n\u001b[1;32m   1386\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1391\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mif\u001b[39;00m feature_idx \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m feature_counter:\n\u001b[1;32m   1279\u001b[0m         feature_counter[feature_idx] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1280\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = make_bow_classifier_pipeline()\n",
    "hyperparam_grid = make_hyperparam_grid()\n",
    "\n",
    "grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    pipeline,\n",
    "    hyperparam_grid,\n",
    "    cv=10,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "grid_searcher.fit(x_train_N, y_train_N)\n",
    "\n",
    "best_model = grid_searcher.best_estimator_\n",
    "best_params = grid_searcher.best_params_\n",
    "best_score = grid_searcher.best_score_\n",
    "\n",
    "yhat_proba_test_N = best_model.predict_proba(x_test_N)\n",
    "\n",
    "np.savetxt(\"yproba1_test.txt\", yhat_proba_test_N[:,1])\n",
    "\n",
    "print(f\"best score: {best_score}; best params:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_bow_feature_extractor__min_df</th>\n",
       "      <th>param_bow_feature_extractor__max_df</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.845625</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.158489</td>\n",
       "      <td>0.854583</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.398107</td>\n",
       "      <td>0.866736</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.630957</td>\n",
       "      <td>0.870486</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.584893</td>\n",
       "      <td>0.855625</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.511886</td>\n",
       "      <td>0.851111</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.845486</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.309573</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_bow_feature_extractor__min_df param_bow_feature_extractor__max_df  \\\n",
       "220                                   1                                 0.5   \n",
       "221                                   1                                 0.5   \n",
       "222                                   1                                 0.5   \n",
       "223                                   1                                 0.5   \n",
       "224                                   1                                 0.5   \n",
       "..                                  ...                                 ...   \n",
       "39                                    4                                 1.0   \n",
       "40                                    4                                 1.0   \n",
       "41                                    4                                 1.0   \n",
       "42                                    4                                 1.0   \n",
       "43                                    4                                 1.0   \n",
       "\n",
       "    param_classifier__C  split0_test_score  rank_test_score  \n",
       "220                 0.1           0.845625              211  \n",
       "221            0.158489           0.854583              163  \n",
       "222            0.251189           0.860833               85  \n",
       "223            0.398107           0.866736               67  \n",
       "224            0.630957           0.870486               31  \n",
       "..                  ...                ...              ...  \n",
       "39             1.584893           0.855625              157  \n",
       "40             2.511886           0.851111              187  \n",
       "41             3.981072           0.845486              223  \n",
       "42             6.309573           0.837500              247  \n",
       "43                 10.0           0.830000              259  \n",
       "\n",
       "[264 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results_df = pd.DataFrame(grid_searcher.cv_results_).copy()\n",
    "\n",
    "param_keys = ['param_bow_feature_extractor__min_df', 'param_bow_feature_extractor__max_df', 'param_classifier__C']\n",
    "\n",
    "grid_search_results_df.sort_values(param_keys, inplace=True)\n",
    "grid_search_results_df[param_keys + ['split0_test_score', 'rank_test_score']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
